{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import glob\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = glob.glob('*.txt')\n",
    "\n",
    "words = []\n",
    "for f in files:\n",
    "    file = open(f)\n",
    "    words.append(file.read())\n",
    "    file.close()\n",
    "\n",
    "words = list(chain.from_iterable(words))\n",
    "words = ''.join(words)[:-1]\n",
    "sentences = words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 97415], ('the', 667723), ('and', 324431), ('a', 322940), ('of', 289409)]\n",
      "Sample data [[279, 174, 436, 7048, 46, 3381, 43, 3, 15, 16, 223, 1129, 72, 1707, 1166, 37, 1, 1308, 1603, 2144, 836, 4, 61, 39, 25, 53, 172, 9, 41, 117, 23, 453, 44, 99, 4, 1, 101, 89, 4, 178, 27, 2991, 8, 1, 4180, 2, 7048, 12, 104, 25, 1654, 399, 22, 2, 92, 1501, 364, 73, 304, 33, 61, 57, 9, 117, 23, 453, 1, 104, 70, 142, 64, 453, 44, 6, 3, 53, 9629, 34013, 9799, 9168, 1, 444, 6, 24, 269, 122, 14, 516, 35, 1237, 24, 12, 127, 72, 244, 322, 184, 86, 2, 273, 56, 3794, 4, 3, 17093, 4180, 26, 62, 13182, 721, 5, 29, 1705, 121, 7048, 414, 51, 70, 25, 69, 501, 1, 302, 95, 218, 4, 10, 3890, 7048, 704, 178, 30, 44, 9168, 12, 2991, 70, 25, 556, 134, 9168, 6, 2098, 5, 29, 1, 118, 17, 56, 2521, 15410, 40, 11272, 56, 1314, 129, 7, 13, 30, 9, 96, 78, 5, 386, 37, 1595, 7, 122, 34, 519, 8], [10, 6, 34, 464, 4, 134, 1, 2219, 4, 205, 105, 25, 1, 168, 3854, 2, 347, 39, 12, 64, 163, 276, 149, 129, 3, 589, 447, 4, 1, 92, 1163, 14102, 1993, 4, 1774, 21, 2, 1774, 4935, 35, 137, 251, 12992, 107, 209, 121, 11, 32, 25, 2173, 4, 114, 2, 114, 69, 87, 21, 1246, 17, 10, 28, 141, 65, 169, 652, 518, 31314, 40, 103, 169, 835, 6074, 16, 1774, 21, 40, 18430, 1489, 1, 2802, 1980, 2826, 40, 2380, 16, 1774, 4935, 2, 65, 1, 145, 781, 1774, 21, 12, 2242, 7103, 408, 610, 164, 10, 19, 16851, 31, 1, 2650, 2, 9, 139, 131, 1528, 47, 1, 2133, 942, 5702, 13, 400, 8, 10, 19, 2, 134, 1, 2133, 125, 24, 212, 285, 1, 2528, 168, 104, 37, 2014, 18354, 171, 19, 9, 137, 108, 17, 942, 5702, 46, 86, 392, 1, 2528, 168, 2040, 104, 2, 31, 222, 8, 2014, 26, 104, 1061, 61, 90, 7, 661, 15980, 435, 10, 6, 334, 950, 205, 1140, 39, 25, 3546, 127, 105, 5, 65, 2, 45, 20, 64, 180, 5, 65, 10, 28, 103, 7836, 308, 61, 6, 2393, 3, 10674, 940, 18, 46, 127, 114, 2, 3, 127, 225, 1, 62, 148, 11, 90, 10, 31, 30, 276, 149, 13, 3, 530, 515, 22, 1, 349, 1, 619, 13, 216, 2509, 61, 269, 493, 5, 231, 55, 16, 1, 486, 19, 388, 18, 23, 181]]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 40000\n",
    "\n",
    "def build_dataset(sentences):\n",
    "    words = ''.join(sentences).split()\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    \n",
    "    unk_count = 0\n",
    "    sent_data = []\n",
    "    for sentence in sentences:\n",
    "        data = []\n",
    "        for word in sentence.split():\n",
    "            if word in dictionary:\n",
    "                index = dictionary[word]\n",
    "            else:\n",
    "                index = 0  # dictionary['UNK']\n",
    "                unk_count = unk_count + 1\n",
    "            data.append(index)\n",
    "        sent_data.append(data)\n",
    "    \n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "    return sent_data, count, dictionary, reverse_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(sentences)\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:2])\n",
    "# del words  # Hint to reduce memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11408957\n"
     ]
    }
   ],
   "source": [
    "skip_window = 3\n",
    "instances = 0\n",
    "for sentence  in data:\n",
    "    instances += len(sentence)-2*skip_window\n",
    "print(instances)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = np.zeros((instances,skip_window*2),dtype=np.int32)\n",
    "labels = np.zeros((instances,1),dtype=np.int32)\n",
    "doc = np.zeros((instances,1),dtype=np.int32)\n",
    "\n",
    "k = 0\n",
    "for doc_id, sentence  in enumerate(data):\n",
    "    for i in range(skip_window, len(sentence)-skip_window):\n",
    "        buffer = sentence[i-skip_window:i+skip_window+1]\n",
    "        del buffer[skip_window]\n",
    "        labels[k] = sentence[i]\n",
    "        context[k] = buffer\n",
    "        doc[k] = doc_id\n",
    "        k += 1\n",
    "        \n",
    "shuffle_idx = np.random.permutation(k)\n",
    "labels = labels[shuffle_idx]\n",
    "doc = doc[shuffle_idx]\n",
    "context = context[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "context_window = 2*skip_window\n",
    "embedding_size = 50 # Dimension of the embedding vector.\n",
    "softmax_width = embedding_size # +embedding_size2+embedding_size3\n",
    "num_sampled = 100 # Number of negative examples to sample.\n",
    "sum_ids = np.repeat(np.arange(batch_size),context_window)\n",
    "\n",
    "len_docs = len(data)\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default(): # , tf.device('/cpu:0')\n",
    "    # Input data.\n",
    "    train_word_dataset = tf.placeholder(tf.int32, shape=[batch_size*context_window])\n",
    "    train_doc_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "\n",
    "    segment_ids = tf.constant(sum_ids, dtype=tf.int32)\n",
    "\n",
    "    word_embeddings = tf.Variable(tf.random_uniform([vocabulary_size,embedding_size],-1.0,1.0))\n",
    "    doc_embeddings = tf.Variable(tf.random_uniform([len_docs,embedding_size],-1.0,1.0))\n",
    "\n",
    "    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, softmax_width],\n",
    "                             stddev=1.0 / np.sqrt(embedding_size)))\n",
    "    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Model.\n",
    "    # Look up embeddings for inputs.\n",
    "    embed_words = tf.segment_sum(tf.nn.embedding_lookup(word_embeddings, train_word_dataset),segment_ids)\n",
    "    embed_docs = tf.nn.embedding_lookup(doc_embeddings, train_doc_dataset)\n",
    "    embed = embed_words+embed_docs#+embed_hash+embed_users\n",
    "\n",
    "    # Compute the softmax loss, using a sample of the negative labels each time.\n",
    "    loss = tf.reduce_mean(tf.nn.nce_loss(softmax_weights, softmax_biases, embed,\n",
    "                                   train_labels, num_sampled, vocabulary_size))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.AdagradOptimizer(0.5).minimize(loss)\n",
    "        \n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(doc_embeddings), 1, keep_dims=True))\n",
    "    normalized_doc_embeddings = doc_embeddings / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# Chunk the data to be passed into the tensorflow Model\n",
    "###########################\n",
    "data_idx = 0\n",
    "def generate_batch(batch_size):\n",
    "    global data_idx\n",
    "\n",
    "    if data_idx+batch_size<len_docs:\n",
    "        batch_labels = labels[data_idx:data_idx+batch_size]\n",
    "        batch_doc_data = doc[data_idx:data_idx+batch_size]\n",
    "        batch_word_data = context[data_idx:data_idx+batch_size]\n",
    "        data_idx += batch_size\n",
    "    else:\n",
    "        overlay = batch_size - (len_docs-data_idx)\n",
    "        batch_labels = np.vstack([labels[data_idx:len_docs],labels[:overlay]])\n",
    "        batch_doc_data = np.vstack([doc[data_idx:len_docs],doc[:overlay]])\n",
    "        batch_word_data = np.vstack([context[data_idx:len_docs],context[:overlay]])\n",
    "        data_idx = overlay\n",
    "    batch_word_data = np.reshape(batch_word_data,(-1,1))\n",
    "\n",
    "    return batch_labels, batch_word_data, batch_doc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 426.157104\n",
      "Average loss at step 50000: 7.854996\n",
      "Average loss at step 100000: 0.641150\n",
      "Average loss at step 150000: 0.603961\n",
      "Average loss at step 200000: 0.594481\n",
      "Average loss at step 250000: 0.589963\n",
      "Average loss at step 300000: 0.586765\n",
      "Average loss at step 350000: 0.584712\n",
      "Average loss at step 400000: 0.583086\n",
      "Average loss at step 450000: 0.582070\n",
      "Average loss at step 500000: 0.581260\n",
      "Average loss at step 550000: 0.580287\n",
      "Average loss at step 600000: 0.579365\n",
      "Average loss at step 650000: 0.579081\n",
      "Average loss at step 700000: 0.578365\n",
      "Average loss at step 750000: 0.578061\n",
      "Average loss at step 800000: 0.577644\n",
      "Average loss at step 850000: 0.577144\n",
      "Average loss at step 900000: 0.576824\n",
      "Average loss at step 950000: 0.576325\n",
      "Average loss at step 1000000: 0.576282\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1000001\n",
    "step_delta = int(num_steps/20)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    average_loss = 0\n",
    "    for step in range(num_steps):\n",
    "        batch_labels, batch_word_data, batch_doc_data\\\n",
    "        = generate_batch(batch_size)\n",
    "        feed_dict = {train_word_dataset : np.squeeze(batch_word_data),\n",
    "                     train_doc_dataset : np.squeeze(batch_doc_data),\n",
    "                     train_labels : batch_labels}\n",
    "        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        average_loss += l\n",
    "        if step % step_delta == 0:\n",
    "            if step > 0:\n",
    "                average_loss = average_loss / step_delta\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print('Average loss at step %d: %f' % (step, average_loss))\n",
    "            average_loss = 0\n",
    "\n",
    "    # Get the weights to save for later\n",
    "#     final_doc_embeddings = normalized_doc_embeddings.eval()\n",
    "    final_word_embeddings = word_embeddings.eval()\n",
    "    final_word_embeddings_out = softmax_weights.eval()\n",
    "    final_doc_embeddings = normalized_doc_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.584714\n",
      "0.526221\n",
      "0.516274\n"
     ]
    }
   ],
   "source": [
    "rand_doc = np.random.randint(len_docs)\n",
    "dist = final_doc_embeddings.dot(final_doc_embeddings[rand_doc][:,None])\n",
    "closest_doc = np.argsort(dist,axis=0)[-4:][::-1]\n",
    "\n",
    "for idx in closest_doc:\n",
    "    print(dist[idx][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'peter crawford discovers a comet on a collision course with the moon but when the government doesn t believe him dumb fact he builds a shelter in deep underground and is drawing lots to see who will go plus is willing to kill to save humanity dumb fact with millions of dollars of technology how could a civilian see what nasa could not plus the ends justifies the means moral of this story is just plain wrong this movie is improbable and totally unbelievable what was running through these people minds why the hell do crap piles like this get the green light some times i wonder who someone has to to get a movie made in this ing town '"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[rand_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow i don t even really remember that much about this movie except that it stunk the plot s basically a girl s parents neglect her so this sicko pokemon pretends to be her dad am i the only one disturbed by that then this weirdo pokemon kidnaps ash s mom to pretend to be the girl s i don t care if he was trying to make the girl happy that s just gross there was no real plot the girl was just a whiny brat who wanted things her own way she played with unowns was the daughter of entei and apparently could grow and shrink in age on a whim with the help of her dad that s pretty much all i can remember but i think you can take it as a hint and not see it or if you do see it don t expect much out of seriously if you want a pokemon movie rent pokemon the first movie '"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is very much not the sort of movie for which john wayne is known he plays a diplomat a man who gets things done through words and persuasion rather than physical action the film moves with a quiet realism through its superficially unexciting story for the open minded the patient and the thoughtful this movie is a rich depiction of an intriguing part of history there are two intertwining stories the big story is of internalised isolationist japan and externalised expansionist america clashing when their interests conflict the small human story is of an outsider barbarian wayne and a civilised geisha s initial hostility and dislike turning to mutual respect and love the human story is a reflection of the greater story of the two nations the movie is very well done and all actors play their roles well the two lead roles are performed to perfection john wayne is excellent as townsend harris striking exactly the right blend of force and negotiation in his dealings with the japanese eiko ando is likewise excellent as the geisha of the title charming and delightful the interaction between her character and john wayne s is particularly well portrayed this is exactly how these two individuals as they are depicted in the film would have behaved the script is very well written it lacks all pomposity and is a realistic depiction of the manner in which the depicted events may have occurred the characters are real people not self consciously great figures from history furthermore the clash of cultures and interests is portrayed with great skill and subtlety indeed the clash of a traditionalist and traditionally powerful isolationist japan and a rising newly powerful nation from across the ocean is summarised very well in one exchange between john wayne and the local japanese baron wayne complains that shipwrecked sailors are beheaded if they land in japan and that passing ships cannot even put into port for water the baron responds that japan just wants to be left alone wayne s character replies that japan is at an increasingly important crossroads of international shipping and that if things continue as before the nation will be regarded as nothing more than a band of brigands infesting an important roadway a very real summary of the way in which the two countries each saw themselves as being in the right and saw the other as being in the wrong the resultant clash between two self righteous peoples with conflicting interests has its reflections throughout history a continuing theme that echoes into the present and on into the future cinematography and the depiction of mid nineteenth century japan before the accelerated growth towards industrialisation that was to follow later in the century is excellent a visual treat and an enlightening insight into japan s ancient civilisation i highly recommend anyone whether a john wayne fan or not to watch this film if you get the chance just be aware that it isn t an action film it is a representation of an interesting place and time in history and a slow boiling love story which much to their surprise comes to dominate the personal lives of the two main characters watch this film on its merits without preconceptions allow yourself to be immersed in its story and you will thoroughly enjoy it all in all an excellent film '"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc[2][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this movie start quite gruesomely with a female being bound and psychologically tortured there s male full frontal nudity dead animal parts dogs licking nipples the female loosing control of her bladder all shot in a gray cold color effective but a little too much we then move on to seeing the btk killer s youth as well as the present and his history of crimes the tension is entirely psychological and the scenes of the killer entering the homes of his victims and talking to them lasts for quite a long time and it s creepy here we don t see fancy or good imagery it looks as if shot with your home camera it doesn t look horrifying but in a way seeing a criminal engage his victims for quite some time before killing them is quite unusual and chilling what this movie doesn t have is any drama really there are some cop scenes every once in a while but there s no excitement in terms of them finding the killer there isn t much of an arc to this story this could have been an effective psychological thriller a study of madness unfortunately the movie is filled with real slaughterhouse footage it s dispersed throughout the movie and comes on suddenly again and again sometimes you don t know it s coming and don t have enough time to look away and that i have to reject i m all for low budget horror movies but i don t tolerate animal suffering it was unnecessary excessive and comes without warning i m glad that lionsgate releases stuff that no one else does but they should have passed on this movie or edited out the animal gore stay away from this garbage '"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc[3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQZIkZTM4SJKkbAYHSZKUzeAgSZKy/X/kUz+ZR1DU0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130f70fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(dist,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "cpus = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "    for i,sentence in enumerate(words.split('\\n')):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(sentence), [i])\n",
    "\n",
    "train_corpus = list(read_corpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(dm=1, dm_concat=0, size=embedding_size, window=skip_window, \n",
    "                negative=5,hs=0, min_count=5, workers=cpus, iter=2)\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 22s, sys: 1.86 s, total: 26min 23s\n",
      "Wall time: 3min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21854570"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.train(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8846234083175659\n",
      "0.8725295066833496\n",
      "0.8673354387283325\n"
     ]
    }
   ],
   "source": [
    "closest_doc2 = model.docvecs.most_similar([model.docvecs[rand_doc]],topn=4)\n",
    "for _, sim in closest_doc2:\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'peter crawford discovers a comet on a collision course with the moon but when the government doesn t believe him dumb fact he builds a shelter in deep underground and is drawing lots to see who will go plus is willing to kill to save humanity dumb fact with millions of dollars of technology how could a civilian see what nasa could not plus the ends justifies the means moral of this story is just plain wrong this movie is improbable and totally unbelievable what was running through these people minds why the hell do crap piles like this get the green light some times i wonder who someone has to to get a movie made in this ing town '"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[rand_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the title of this documentary is very misleading at no time during the documentary do they show how the introduction of the nile perch fish into lake victoria has cause any of the problems facing the town of mwanza tanzania the film tries to place the problems of tanzania on an environmental cause but the truth of that matter is the problems stem from a parasitic outside force the documentary is very slowing paced with no narrative what so ever instead it relies on small blips of text between none related segments to display bits of information that do little to add or expand of the subject matter there are only two attempts to discus the environmental effects of the nile perch fish one is a small segment about seconds long where they interview the factory managers where the fish is processed and he briefly mentions how years ago the nile perch was introduced into the lake and it consumed the other fish species the film maker makes no attempt to follow up on the matter or go deeper into it the second attempt is when within this documentary they film the showing of another documentary that is discussing the environmental impact the nile perch has introduced and again no real attempt is made to expand on just how devastating the problem has become the subject matter that this documentary does delve into has nothing to do with the perch fish itself and more to do with the problems facing most african countries the film tries to link the introduction of the perch fish with aids poverty and pollution in tanzania but never makes a direct connection as any intelligent person well read with problems in africa the problems shown here are not unique to tanzania but affect most of africa and have nothing to do with the fish it would have been great if the film makers would have shown how the local economy or life was before the fish was introduced and how it has been negatively impacted by the introduction of the fish but they don t the fact of the matter is that many of the people they interview say that the fish has provided jobs and opportunity for many yes things are bad within the town of mwanza but they are far worst in other parts of the country and continent for that matter a weak attempt by the documentary makers to link the fish to famine problems in tanzania is quickly discredited by the documentary itself first off tanzania is a very large country and lake victoria is only a small portion of the country many of the individuals interview actually say that they can to mwanza the fishing town on the lake to find a job and feed their families because things were so bad in other parts of the country this documentary is very weak has no narrative and makes no attempt to actually link anything they display to the nile perch it plays on people s emotions by displaying images of the devastation of poverty famine and aids making no attempt to show you how any of this is unique to the lake victoria region of tanzania or directly related to the perch fish the fact is most of the problems have more to do with war globalization and christianity than and environmental effect of the perch fish itself '"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc2[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this could have been great the voice overs are exactly right and fit the characters to a t one small problem though the look of the characters mostly the supporting or guest characters look exactly the same the same bored look on every face only with minor changes such as hairlines or weight size it looks kind of odd to see a really big guest star s voice coming out of a lifeless form like the characters here if i am not mistaken kathy griffin did a voice over for this show and it looked too odd to be funny there is a few other problems one being the family plot the simpsons did it much better where you could actually buy most of the situations the characters got themselves into here we get too much annoying diversions like someone having a weird fantasy and then we are supposed to find that funny but for some reason the delivery is a bit off as you can probably tell it is hard for me to put a finger on exactly what is wrong with this show because it basically nothing more than a clone of the simpsons or even more married with children if i should point a finger on what is totally wrong with this it probably is it s repetitiveness peter griffin is not really a bright character but neither are any of the others lois should have been named lois lame because she is sort of one dimensional seth green as the kind of retarded son is the best thing about this show and that is the most stereotypical part on the show so what more can i say there isn t exactly anything wrong with this show but in the long run you have to admit that it takes a lot of work to do what the simpsons has done for almost two decades '"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc2[2][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i like many folks believe the epic lonesome dove was one of the best westerns ever produced maybe the best and realizing that most sequels in this case a prequel are certain to disappoint my expectations were low comanche moon met that expectation with its marginal directing and acting poor casting and frankly a lousy script lonesome dove created western heroes of captains mccrae and call due to incredibly strong performances by robert duvall and tommy lee jones prior to living in lonesome dove we believed they bravely fought to rid texas of bandits and savage indians during their rangering years if i had only seen comanche moon i would think these two boneheads were a couple of incompetent cowardly idiots in lonesome dove call and mccrae supposedly chased blue duck all over texas and never managed to capture or kill him in comanche moon a shot to call s boot heel convinced him to settle down and raise cattle there wasn t a decent fistfight or gun fight in the entire miniseries the best punch was mccrea sucker punching inez scull a funny scene but out of character for mccrae where was mccrae s wit and charm clara s love for mccrae a drunken unshaven slob and philanderer was completely implausible and maggie s love for call a dispassionate and sullen loner defies logic the cinematography was excellent superior to the original credit goes not only to hd technology but the cinematographer the comanche moon miniseries was better than anything else on tv for three nights but sadly that s not saying much '"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[closest_doc2[3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
